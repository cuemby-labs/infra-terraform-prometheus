additionalPrometheusRulesMap:
  rule-name:
    groups:
    - name: rules-cuemby
      rules:
        #OpenEBS
        - alert: OpenebsUsedPoolCapacity
          expr: openebs_used_pool_capacity_percent > 90
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: OpenEBS used pool capacity (instance {{ $labels.instance }})
            description: "OpenEBS Pool use more than 90% of his capacity\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Host and hardware : node-exporter
        - alert: HostOutOfMemory
          expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Host out of memory (instance {{ $labels.instance }})
            description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Host memory under memory pressure
        - alert: HostMemoryUnderMemoryPressure
          expr: (rate(node_vmstat_pgmajfault[1m]) > 1000) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Host memory under memory pressure (instance {{ $labels.instance }})
            description: "The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Host unusual network throughput in
        - alert: HostUnusualNetworkThroughputIn
          expr: (sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Host unusual network throughput in (instance {{ $labels.instance }})
            description: "Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Host out of disk space
        - alert: HostOutOfDiskSpace
          expr: ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Host out of disk space (instance {{ $labels.instance }})
            description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Host disk will fill in 24 hours
        - alert: HostDiskWillFillIn24Hours
          expr: ((node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
            description: "Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Host high CPU load
        - alert: HostHighCpuLoad
          expr: (sum by (instance) (avg by (mode, instance) (rate(node_cpu_seconds_total{mode!="idle"}[2m]))) > 0.8) * on(instance) group_left (nodename) node_uname_info{nodename=~".+"}
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Host high CPU load (instance {{ $labels.instance }})
            description: "CPU load is > 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Cloudflare http 4xx error rate
        - alert: CloudflareHttp4xxErrorRate
          expr: (sum by(zone) (rate(cloudflare_zone_requests_status{status=~"^4.."}[15m])) / on (zone) sum by (zone) (rate(cloudflare_zone_requests_status[15m]))) * 100 > 5
          for: 0m
          labels:
            severity: warning
          annotations:
            summary: Cloudflare http 4xx error rate (instance {{ $labels.instance }})
            description: "Cloudflare high HTTP 4xx error rate (> 5% for domain {{ $labels.zone }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Cloudflare http 5xx error rate
        - alert: CloudflareHttp5xxErrorRate
          expr: (sum by (zone) (rate(cloudflare_zone_requests_status{status=~"^5.."}[5m])) / on (zone) sum by (zone) (rate(cloudflare_zone_requests_status[5m]))) * 100 > 5
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Cloudflare http 5xx error rate (instance {{ $labels.instance }})
            description: "Cloudflare high HTTP 5xx error rate (> 5% for domain {{ $labels.zone }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        # Alerta si el certificado expira en 7 d√≠as
        - alert: SSLCertificateExpiringSoon
          expr: probe_ssl_earliest_cert_expiry - time() < 86400 * 7
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "SSL Certificate is expiring soon (instance {{ $labels.instance }})"
            description: "SSL Certificate for {{ $labels.instance }} expires in less than 7 days."
        #Blackbox SSL certificate will expire soon
        - alert: BlackboxSslCertificateWillExpireSoon
          expr: 0 <= round((last_over_time(probe_ssl_earliest_cert_expiry[10m]) - time()) / 86400, 0.1) < 3
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Blackbox SSL certificate will expire soon (instance {{ $labels.instance }})
            description: "SSL certificate expires in less than 3 days\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        #Blackbox probe HTTP failure
        - alert: BlackboxProbeHttpFailure
          expr: probe_http_status_code <= 199 OR probe_http_status_code >= 400
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Blackbox probe HTTP failure (instance {{ $labels.instance }})
            description: "HTTP status code is not 200-399\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
defaultRules:
  rules:
    kubeProxy: false
prometheus:
  prometheusSpec:
    additionalScrapeConfigs:
      - job_name: 'blackbox'
        metrics_path: /probe
        params:
          module: [http_2xx]  # Look for a HTTP 200 response.
        static_configs:
          - targets:
            # Target to probe with https.
            #- http://example.com:8080 # Target to probe with http on port 8080.
            # - http://prometheus.io    # Target to probe with http.
            - https://console.dev.cuemby.net
            - https://walrus.dev.cuemby.net/
            - https://harbor.dev.cuemby.net/api/
            - https://harbor.dev.cuemby.net/service/
            - https://harbor.dev.cuemby.net/v2/
            - https://harbor.dev.cuemby.net/chartrepo/
            - https://harbor.dev.cuemby.net/c/
            - https://harbor.dev.cuemby.net/
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: prometheus-blackbox-exporter:9115  # The blackbox exporter's real hostname:port.
      - job_name: 'blackbox_exporter'  # collect blackbox exporter's operational metrics.
        static_configs:
          - targets: ['prometheus-blackbox-exporter:9115']
      - job_name: "blackbox-external-targets"
        metrics_path: /probe
        params:
          module: [http_2xx]
        static_configs:
          - targets:
            - https://www.google.com
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: prometheus-blackbox-exporter:9115
      - job_name: "blackbox-kubernetes-services"
        metrics_path: /probe
        params:
          module: [http_2xx]
        kubernetes_sd_configs:
        - role: service
        relabel_configs:
        # Example relabel to probe only some services that have "example.io/should_be_probed = true" annotation
        #  - source_labels: [__meta_kubernetes_service_annotation_example_io_should_be_probed]
        #    action: keep
        #    regex: true
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement:  prometheus-blackbox-exporter:9115
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            target_label: kubernetes_service_name
  service:
    type: ClusterIP
  ingress:
    hosts:
      - prometheus.core-dev.cuemby.net
    annotations:
      cert-manager.io/issuer: origin-ca-issuer
      cert-manager.io/issuer-kind: ClusterOriginIssuer
      cert-manager.io/issuer-group: cert-manager.k8s.cloudflare.com
      external-dns.alpha.kubernetes.io/cloudflare-proxied: 'true'
      external-dns.alpha.kubernetes.io/hostname: prometheus.core-dev.cuemby.net
    enabled: true
    ingressClassName: nginx
    tls:
      - hosts:
        - prometheus.core-dev.cuemby.net
        secretName: prometheus-core-dev-cuemby-net
alertmanager:
  enabled: true
  config:
    global:
      resolve_timeout: 10m
    route:
      group_by: ['job']
      group_wait: 5m
      group_interval: 15m
      repeat_interval: 1h
      receiver: 'webhook'
    receivers:
    - name: 'webhook'
      webhook_configs:
      - url: 'http://prometheus-msteams:2000/alerts'
        send_resolved: true
  alertmanagerSpec:
    configSecret: myalertmanager
  service:
    type: ClusterIP
  ingress:
    hosts:
      - alertmanager.core-dev.cuemby.net
    annotations:
      cert-manager.io/issuer: origin-ca-issuer
      cert-manager.io/issuer-kind: ClusterOriginIssuer
      cert-manager.io/issuer-group: cert-manager.k8s.cloudflare.com
      external-dns.alpha.kubernetes.io/cloudflare-proxied: 'true'
      external-dns.alpha.kubernetes.io/hostname: alertmanager.core-dev.cuemby.net
    enabled: true
    ingressClassName: nginx
    tls:
      - hosts:
        - alertmanager.core-dev.cuemby.net
        secretName: alertmanager-core-dev-cuemby-net
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeEtcd:
  enabled: false